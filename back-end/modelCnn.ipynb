{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.utils import plot_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_files = ['open_eyes.pickle', 'closed_eyes.pickle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for pickle_file in pickle_files:\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        save = pickle.load(f)\n",
    "        if i == 0:\n",
    "            train_dataset = save['train_dataset']\n",
    "            train_labels = save['train_labels']\n",
    "            test_dataset = save['test_dataset']\n",
    "            test_labels = save['test_labels']\n",
    "        else:\n",
    "            print(\"here\")\n",
    "            train_dataset = np.concatenate((train_dataset, save['train_dataset']))\n",
    "            train_labels = np.concatenate((train_labels, save['train_labels']))\n",
    "            test_dataset = np.concatenate((test_dataset, save['test_dataset']))\n",
    "            test_labels = np.concatenate((test_labels, save['test_labels']))\n",
    "        del save  \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (3876, 24, 24, 1) (3876, 1)\n",
      "Test set (970, 24, 24, 1) (970, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset\n",
    "\n",
    "Y_train = train_labels\n",
    "\n",
    "X_test = test_dataset\n",
    "\n",
    "Y_test = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3876, 24, 24, 1)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3876 train samples, 1 channels, 24x24\n",
      "970  test samples, 1 channels, 24x24\n"
     ]
    }
   ],
   "source": [
    "print(\"{1} train samples, {4} channel{0}, {2}x{3}\".format(\"\" if X_train.shape[1] == 1 else \"s\", *X_train.shape))\n",
    "print(\"{1}  test samples, {4} channel{0}, {2}x{3}\".format(\"\" if X_test.shape[1] == 1 else \"s\", *X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3876 1 24 24\n"
     ]
    }
   ],
   "source": [
    "_, img_rows, img_cols, img_channels, = X_train.shape\n",
    "print(_, img_channels, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "noOfClasses = 1\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3, 3), padding='same',input_shape=(img_rows, img_cols, img_channels)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(24, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Convolution2D(32, (3, 3), padding='same',input_shape=(img_rows, img_cols, img_channels)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(24, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(noOfClasses))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3876, 24, 24, 1) (3876, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970, 24, 24, 1) (970, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "130/130 - 5s - loss: 0.6635 - accuracy: 0.5782 - val_loss: 0.6042 - val_accuracy: 0.6608\n",
      "Epoch 2/12\n",
      "130/130 - 6s - loss: 0.6124 - accuracy: 0.6672 - val_loss: 0.5639 - val_accuracy: 0.7258\n",
      "Epoch 3/12\n",
      "130/130 - 6s - loss: 0.5640 - accuracy: 0.7072 - val_loss: 0.4711 - val_accuracy: 0.7691\n",
      "Epoch 4/12\n",
      "130/130 - 5s - loss: 0.4636 - accuracy: 0.7807 - val_loss: 0.3612 - val_accuracy: 0.8546\n",
      "Epoch 5/12\n",
      "130/130 - 6s - loss: 0.3464 - accuracy: 0.8568 - val_loss: 0.2786 - val_accuracy: 0.8825\n",
      "Epoch 6/12\n",
      "130/130 - 5s - loss: 0.2730 - accuracy: 0.8916 - val_loss: 0.2221 - val_accuracy: 0.9072\n",
      "Epoch 7/12\n",
      "130/130 - 5s - loss: 0.2270 - accuracy: 0.9143 - val_loss: 0.2136 - val_accuracy: 0.9155\n",
      "Epoch 8/12\n",
      "130/130 - 5s - loss: 0.2102 - accuracy: 0.9203 - val_loss: 0.1706 - val_accuracy: 0.9423\n",
      "Epoch 9/12\n",
      "130/130 - 5s - loss: 0.1879 - accuracy: 0.9291 - val_loss: 0.1602 - val_accuracy: 0.9495\n",
      "Epoch 10/12\n",
      "130/130 - 5s - loss: 0.1709 - accuracy: 0.9391 - val_loss: 0.2477 - val_accuracy: 0.8959\n",
      "Epoch 11/12\n",
      "130/130 - 6s - loss: 0.1785 - accuracy: 0.9288 - val_loss: 0.1289 - val_accuracy: 0.9526\n",
      "Epoch 12/12\n",
      "130/130 - 6s - loss: 0.1553 - accuracy: 0.9412 - val_loss: 0.1107 - val_accuracy: 0.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17544448308>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=2, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1107 - accuracy: 0.9588\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.11070766299962997\n",
      "Test accuracy: 0.9587628841400146\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"driverDrowsinessModel.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
